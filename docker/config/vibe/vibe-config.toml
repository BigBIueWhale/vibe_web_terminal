# Vibe CLI configuration for Docker container
#
# IMPORTANT: Ollama Load Balancer must listen on 172.17.0.1:11434 (docker0)
# so that containers can reach it.

# =============================================================================
# Core Settings
# =============================================================================

# Set at container start by VIBE_MODE env var (local|cloud)
# "devstral-local" = Ollama, "devstral-cloud" = Mistral API
active_model = "__VIBE_ACTIVE_MODEL__"

# Disable auto-update (container image is immutable)
enable_auto_update = false
enable_update_checks = false

# Ollama model has 104K context â€” compact well before hitting it
# (new Vibe default is 200K, which would overflow our local model)
auto_compact_threshold = 95000

# =============================================================================
# Provider Configuration
# =============================================================================

# --- Local Ollama ---
[[providers]]
name = "ollama-docker0"
# Containers reach host at 172.17.0.1 (Docker bridge IP)
api_base = "http://172.17.0.1:11434/v1"
api_key_env_var = "OLLAMA_API_KEY"
api_style = "openai"
backend = "generic"

# --- Mistral Cloud ---
[[providers]]
name = "mistral-cloud"
api_base = "https://api.mistral.ai/v1"
api_key_env_var = "MISTRAL_API_KEY"
backend = "mistral"

# =============================================================================
# Model Configuration
# =============================================================================

# --- Local Ollama ---
[[models]]
name = "devstral-vibe"
provider = "ollama-docker0"
alias = "devstral-local"
input_price = 0.0
output_price = 0.0

# --- Mistral Cloud ---
[[models]]
name = "devstral-small-2501"
provider = "mistral-cloud"
alias = "devstral-cloud"
input_price = 0.10
output_price = 0.30
